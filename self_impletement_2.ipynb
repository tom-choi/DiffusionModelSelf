{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from diffusers import DDPMScheduler, UNet2DModel\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = torchvision.datasets.FashionMNIST(root=\"fashion_mnist/\", train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "\n",
    "# Feed it into a dataloader (batch size 8 here just for demo)\n",
    "train_dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# View some examples\n",
    "x, y = next(iter(train_dataloader))\n",
    "print('Input shape:', x.shape)\n",
    "print('Labels:', y)\n",
    "plt.imshow(torchvision.utils.make_grid(x)[0], cmap='Greys');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassConditionedUnet(nn.Module):\n",
    "  def __init__(self, num_classes=10, class_emb_size=4):\n",
    "    super().__init__()\n",
    "    \n",
    "    # The embedding layer will map the class label to a vector of size class_emb_size\n",
    "    self.class_emb = nn.Embedding(num_classes, class_emb_size)\n",
    "\n",
    "    # Self.model is an unconditional UNet with extra input channels to accept the conditioning information (the class embedding)\n",
    "    self.model = UNet2DModel(\n",
    "        sample_size=28,           # the target image resolution\n",
    "        in_channels=1 + class_emb_size, # Additional input channels for class cond.\n",
    "        out_channels=1,           # the number of output channels\n",
    "        layers_per_block=2,       # how many ResNet layers to use per UNet block\n",
    "        block_out_channels=(32, 64, 64), \n",
    "        down_block_types=( \n",
    "            \"DownBlock2D\",        # a regular ResNet downsampling block\n",
    "            \"AttnDownBlock2D\",    # a ResNet downsampling block with spatial self-attention\n",
    "            \"AttnDownBlock2D\",\n",
    "        ), \n",
    "        up_block_types=(\n",
    "            \"AttnUpBlock2D\", \n",
    "            \"AttnUpBlock2D\",      # a ResNet upsampling block with spatial self-attention\n",
    "            \"UpBlock2D\",          # a regular ResNet upsampling block\n",
    "          ),\n",
    "    )\n",
    "\n",
    "  # Our forward method now takes the class labels as an additional argument\n",
    "  def forward(self, x, t, class_labels):\n",
    "    # Shape of x:\n",
    "    bs, ch, w, h = x.shape\n",
    "    \n",
    "    # class conditioning in right shape to add as additional input channels\n",
    "    class_cond = self.class_emb(class_labels) # Map to embedding dimension\n",
    "    class_cond = class_cond.view(bs, class_cond.shape[1], 1, 1).expand(bs, class_cond.shape[1], w, h)\n",
    "    # x is shape (bs, 1, 28, 28) and class_cond is now (bs, 4, 28, 28)\n",
    "\n",
    "    # Net input is now x and class cond concatenated together along dimension 1\n",
    "    net_input = torch.cat((x, class_cond), 1) # (bs, 5, 28, 28)\n",
    "\n",
    "    # Feed this to the UNet alongside the timestep and return the prediction\n",
    "    return self.model(net_input, t).sample # (bs, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scheduler\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule='squaredcos_cap_v2')\n",
    "     \n",
    "\n",
    "#@markdown Training loop (10 Epochs):\n",
    "\n",
    "# Redefining the dataloader to set the batch size higher than the demo of 8\n",
    "train_dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# How many runs through the data should we do?\n",
    "n_epochs = 10\n",
    "\n",
    "# Our network \n",
    "net = ClassConditionedUnet().to(device)\n",
    "\n",
    "# Our loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# The optimizer\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-3) \n",
    "\n",
    "# Keeping a record of the losses for later viewing\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練代碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for x, y in tqdm(train_dataloader):\n",
    "        \n",
    "        # Get some data and prepare the corrupted version\n",
    "        x = x.to(device) * 2 - 1 # Data on the GPU (mapped to (-1, 1))\n",
    "        y = y.to(device)\n",
    "        noise = torch.randn_like(x)\n",
    "        timesteps = torch.randint(0, 999, (x.shape[0],)).long().to(device)\n",
    "        noisy_x = noise_scheduler.add_noise(x, noise, timesteps)\n",
    "\n",
    "        # Get the model prediction\n",
    "        pred = net(noisy_x, timesteps, y) # Note that we pass in the labels y\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(pred, noise) # How close is the output to the noise\n",
    "\n",
    "        # Backprop and update the params:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # Store the loss for later\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # Print out the average of the last 100 loss values to get an idea of progress:\n",
    "    avg_loss = sum(losses[-100:])/100\n",
    "    print(f'Finished epoch {epoch}. Average of the last 100 loss values: {avg_loss:05f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the loss curve\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown Sampling some different digits:\n",
    "\n",
    "# Prepare random x to start from, plus some desired labels y\n",
    "x = torch.randn(80, 1, 28, 28).to(device)\n",
    "y = torch.tensor([[i]*8 for i in range(10)]).flatten().to(device)\n",
    "\n",
    "# Sampling loop\n",
    "for i, t in tqdm(enumerate(noise_scheduler.timesteps)):\n",
    "\n",
    "    # Get model pred\n",
    "    with torch.no_grad():\n",
    "        residual = net(x, t, y)  # Again, note that we pass in our labels y\n",
    "\n",
    "    # Update sample with step\n",
    "    x = noise_scheduler.step(residual, t, x).prev_sample\n",
    "\n",
    "# Show the results\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "ax.imshow(torchvision.utils.make_grid(x.detach().cpu().clip(-1, 1), nrow=8)[0], cmap='Greys')\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
